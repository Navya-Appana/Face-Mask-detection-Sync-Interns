{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b67e8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7fadd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3450b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRECTORY = r\"C:\\Users\\navya\\Downloads\\Face-Mask-Detection-master\\Face-Mask-Detection-master\\dataset\"\n",
    "CATEGORIES = [\"with_mask\", \"without_mask\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80cf666d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading images...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b956c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30e194dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in CATEGORIES:\n",
    "    path = os.path.join(DIRECTORY, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        image = load_img(img_path, target_size=(224, 224))\n",
    "        image = img_to_array(image)\n",
    "        image = preprocess_input(image)\n",
    "        data.append(image)\n",
    "        labels.append(category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9faf7e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels,test_size=0.20, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8de37f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(rotation_range=20,zoom_range=0.15,width_shift_range=0.2,height_shift_range=0.2,shear_range=0.15,horizontal_flip=True,fill_mode=\"nearest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b7cde6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False,input_tensor=Input(shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c2d3f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e16a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6288b52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f597067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navya\\anaconda3\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# compile our model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c28e73df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training head...\n",
      "Epoch 1/20\n",
      "287/287 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.9329WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 71 batches). You may need to use the repeat() function when building your dataset.\n",
      "287/287 [==============================] - 351s 1s/step - loss: 0.2151 - accuracy: 0.9329 - val_loss: 0.0651 - val_accuracy: 0.9852\n",
      "Epoch 2/20\n",
      "287/287 [==============================] - 222s 775ms/step - loss: 0.0692 - accuracy: 0.9798\n",
      "Epoch 3/20\n",
      "287/287 [==============================] - 206s 716ms/step - loss: 0.0491 - accuracy: 0.9846\n",
      "Epoch 4/20\n",
      "287/287 [==============================] - 255s 887ms/step - loss: 0.0388 - accuracy: 0.9904\n",
      "Epoch 5/20\n",
      "287/287 [==============================] - 243s 845ms/step - loss: 0.0353 - accuracy: 0.9890\n",
      "Epoch 6/20\n",
      "287/287 [==============================] - 235s 817ms/step - loss: 0.0307 - accuracy: 0.9914\n",
      "Epoch 7/20\n",
      "287/287 [==============================] - 274s 957ms/step - loss: 0.0308 - accuracy: 0.9903\n",
      "Epoch 8/20\n",
      "287/287 [==============================] - 207s 720ms/step - loss: 0.0251 - accuracy: 0.9921\n",
      "Epoch 9/20\n",
      "287/287 [==============================] - 236s 821ms/step - loss: 0.0243 - accuracy: 0.9930\n",
      "Epoch 10/20\n",
      "287/287 [==============================] - 264s 921ms/step - loss: 0.0240 - accuracy: 0.9923\n",
      "Epoch 11/20\n",
      "287/287 [==============================] - 242s 844ms/step - loss: 0.0177 - accuracy: 0.9947\n",
      "Epoch 12/20\n",
      "287/287 [==============================] - 218s 759ms/step - loss: 0.0206 - accuracy: 0.9926\n",
      "Epoch 13/20\n",
      "287/287 [==============================] - 1242s 4s/step - loss: 0.0158 - accuracy: 0.9954\n",
      "Epoch 14/20\n",
      "287/287 [==============================] - 586s 2s/step - loss: 0.0172 - accuracy: 0.9954\n",
      "Epoch 15/20\n",
      "287/287 [==============================] - 233s 813ms/step - loss: 0.0156 - accuracy: 0.9959\n",
      "Epoch 16/20\n",
      "287/287 [==============================] - 1607s 6s/step - loss: 0.0146 - accuracy: 0.9956\n",
      "Epoch 17/20\n",
      "287/287 [==============================] - 209s 726ms/step - loss: 0.0137 - accuracy: 0.9961\n",
      "Epoch 18/20\n",
      "287/287 [==============================] - 230s 801ms/step - loss: 0.0145 - accuracy: 0.9951\n",
      "Epoch 19/20\n",
      "287/287 [==============================] - 252s 876ms/step - loss: 0.0121 - accuracy: 0.9963\n",
      "Epoch 20/20\n",
      "287/287 [==============================] - 230s 801ms/step - loss: 0.0128 - accuracy: 0.9964\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(\n",
    "    aug.flow(trainX, trainY, batch_size=BS),\n",
    "    steps_per_epoch=len(trainX) // BS,\n",
    "    validation_data=(testX, testY),\n",
    "    validation_steps=len(testX) // BS,\n",
    "    epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37118922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "72/72 [==============================] - 50s 692ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   with_mask       0.99      1.00      1.00      1149\n",
      "without_mask       1.00      0.99      1.00      1151\n",
      "\n",
      "    accuracy                           1.00      2300\n",
      "   macro avg       1.00      1.00      1.00      2300\n",
      "weighted avg       1.00      1.00      1.00      2300\n",
      "\n",
      "[INFO] saving mask detector model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (20,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25344/407620036.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"train_acc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"val_acc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training Loss and Accuracy\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch #\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3017\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3018\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3019\u001b[1;33m     return gca().plot(\n\u001b[0m\u001b[0;32m   3020\u001b[0m         \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3021\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \"\"\"\n\u001b[0;32m   1604\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 501\u001b[1;33m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[0;32m    502\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[0;32m    503\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (20,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make predictions on the testing set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(testX, batch_size=BS)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testY.argmax(axis=1), predIdxs,target_names=lb.classes_))\n",
    "\n",
    "# serialize the model to disk\n",
    "print(\"[INFO] saving mask detector model...\")\n",
    "model.save(\"mask_detector.model\", save_format=\"h5\")\n",
    "\n",
    "# plot the training loss and accuracy\n",
    "N = EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8cdd84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
